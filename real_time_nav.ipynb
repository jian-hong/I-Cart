{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1eb886",
   "metadata": {},
   "source": [
    "## Real-time Visual Navigation using Webcam in VS Code\n",
    "\n",
    "This notebook uses your local machine's webcam to find a safe path in real-time.\n",
    "\n",
    "**Instructions:**\n",
    "1.  **Run this cell first** to install the necessary libraries for this project.\n",
    "2.  Run the subsequent cells in order to load the models.\n",
    "3.  Run the final \"Main Real-time Processing Loop\" cell to start your webcam.\n",
    "4.  A new window titled \"Real-time Navigation\" will appear.\n",
    "5.  **To stop the program, click on the video window and press the 'q' key.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3969006",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5601cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd824a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models... This may take a moment.\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oojia\\Downloads\\IDP\\ven\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172: UserWarning: The following named arguments are not valid for `OneFormerImageProcessor.__init__` and were ignored: '_max_size'\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found walkable class IDs: [3, 6, 11, 13, 52, 94]\n",
      "Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading models... This may take a moment.\")\n",
    "# Check for GPU (highly recommended for performance)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- YOLOv11 for Object Detection ---\n",
    "yolo_model = YOLO(\"yolo11n.pt\")\n",
    "yolo_model.to(device)\n",
    "\n",
    "# --- OneFormer for Semantic Segmentation ---\n",
    "oneformer_processor = OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_ade20k_swin_large\")\n",
    "oneformer_model = OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_ade20k_swin_large\")\n",
    "oneformer_model.to(device)\n",
    "\n",
    "# Identify all plausible walkable surfaces from the model's configuration\n",
    "walkable_keywords = [\"floor\", \"path\", \"road\", \"sidewalk\", \"pavement\", \"ground\"]\n",
    "walkable_ids = [\n",
    "    k for k, v in oneformer_model.config.id2label.items()\n",
    "    if any(keyword in v.lower() for keyword in walkable_keywords)\n",
    "]\n",
    "print(f\"Found walkable class IDs: {walkable_ids}\")\n",
    "\n",
    "print(\"Models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daee4ec",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865bd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scene(frame, yolo_model, oneformer_processor, oneformer_model, walkable_ids, device):\n",
    "    \"\"\"Performs segmentation and object detection on a single frame.\"\"\"\n",
    "    # 1. Semantic Segmentation\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    inputs = oneformer_processor(images=image_pil, task_inputs=[\"semantic\"], return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = oneformer_model(**inputs)\n",
    "    predicted_map = oneformer_processor.post_process_semantic_segmentation(outputs, target_sizes=[image_pil.size[::-1]])[0]\n",
    "    walkable_mask = np.isin(predicted_map.cpu().numpy(), walkable_ids).astype(np.uint8)\n",
    "\n",
    "    # 2. Object Detection\n",
    "    yolo_results = yolo_model(frame, verbose=False)\n",
    "    human_boxes = []\n",
    "    obstacle_boxes = []\n",
    "    for result in yolo_results:\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls[0])\n",
    "            class_name = yolo_model.names[class_id]\n",
    "            if class_name == 'person':\n",
    "                human_boxes.append(box.xyxy[0].cpu().numpy().astype(int))\n",
    "            else:\n",
    "                obstacle_boxes.append(box.xyxy[0].cpu().numpy().astype(int))\n",
    "    \n",
    "    # 3. Combine Masks for \"Safe Path\"\n",
    "    obstacle_mask = np.zeros_like(walkable_mask)\n",
    "    all_obstacles = human_boxes + obstacle_boxes\n",
    "    for box in all_obstacles:\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(obstacle_mask, (x1, y1), (x2, y2), 1, -1)\n",
    "    safe_path_mask = cv2.bitwise_and(walkable_mask, cv2.bitwise_not(obstacle_mask))\n",
    "    \n",
    "    return safe_path_mask, human_boxes, obstacle_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d3a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_blockage(boxes, region_x_start, region_x_end, frame_height):\n",
    "    \"\"\"Checks if any box overlaps with a specified vertical region in the bottom half of the frame.\"\"\"\n",
    "    for x1, y1, x2, y2 in boxes:\n",
    "        # Consider only boxes that are at least partially in the lower (navigation) half of the frame\n",
    "        if y2 > frame_height / 2:\n",
    "            # Check for horizontal overlap with the central region\n",
    "            # AABB overlap condition: (box1.left < box2.right) and (box1.right > box2.left)\n",
    "            if x1 < region_x_end and x2 > region_x_start:\n",
    "                return True # Found a blocking object\n",
    "    return False # No blocking objects in the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c20188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_navigation_decision(safe_path_mask, human_boxes, obstacle_boxes, frame_shape):\n",
    "    \"\"\"Makes an intelligent navigation decision based on the safe path and detected objects.\"\"\"\n",
    "    H, W = frame_shape\n",
    "    left_boundary = W // 3\n",
    "    right_boundary = 2 * W // 3\n",
    "    \n",
    "    # Analyze safe path in the lower half of the frame (where the robot would move)\n",
    "    navigation_area = safe_path_mask[H//2:, :]\n",
    "    left_region = navigation_area[:, :left_boundary]\n",
    "    center_region = navigation_area[:, left_boundary:right_boundary]\n",
    "    right_region = navigation_area[:, right_boundary:]\n",
    "\n",
    "    left_score = cv2.countNonZero(left_region)\n",
    "    center_score = cv2.countNonZero(center_region)\n",
    "    right_score = cv2.countNonZero(right_region)\n",
    "\n",
    "    # Thresholds for making decisions\n",
    "    center_threshold = center_region.size * 0.20  # 20% of center must be clear to move forward\n",
    "    side_threshold = left_region.size * 0.15      # 15% of a side must be clear to consider turning\n",
    "\n",
    "    # 1. Primary Check: Is the way forward clear based on the segmentation mask?\n",
    "    if center_score > center_threshold:\n",
    "        return \"Move Forward\"\n",
    "\n",
    "    # 2. If blocked, determine the cause by checking for objects in the central path\n",
    "    is_human_blocking = check_for_blockage(human_boxes, left_boundary, right_boundary, H)\n",
    "    is_obstacle_blocking = check_for_blockage(obstacle_boxes, left_boundary, right_boundary, H)\n",
    "    \n",
    "    if is_human_blocking:\n",
    "        return \"Waiting for human...\"\n",
    "    \n",
    "    if is_obstacle_blocking:\n",
    "        # Path is blocked by a static object, suggest a more drastic action\n",
    "        return \"Obstacle Blockage. Scan 360\"\n",
    "\n",
    "    # 3. If blocked but not by a detected object (e.g., a wall), find an alternate path\n",
    "    if left_score > right_score and left_score > side_threshold:\n",
    "        return \"Turn Left\"\n",
    "        \n",
    "    if right_score > left_score and right_score > side_threshold:\n",
    "        return \"Turn Right\"\n",
    "\n",
    "    # 4. If no other option, declare a full stop\n",
    "    return \"STOP - FULLY BLOCKED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8584c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_output(frame, safe_path_mask, human_boxes, obstacle_boxes, decision):\n",
    "    \"\"\"Draws all annotations and text onto the frame for display.\"\"\"\n",
    "    H, W, _ = frame.shape\n",
    "    left_boundary = W // 3\n",
    "    right_boundary = 2 * W // 3\n",
    "\n",
    "    # Create a green overlay for the safe path\n",
    "    safe_path_viz = np.zeros_like(frame)\n",
    "    if safe_path_mask is not None:\n",
    "        safe_path_viz[safe_path_mask == 1] = (0, 255, 0) # Green\n",
    "    output_frame = cv2.addWeighted(frame, 0.7, safe_path_viz, 0.3, 0)\n",
    "\n",
    "    # Draw boxes for humans (blue) and obstacles (red)\n",
    "    for x1, y1, x2, y2 in human_boxes:\n",
    "        cv2.rectangle(output_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(output_frame, \"Human\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    for x1, y1, x2, y2 in obstacle_boxes:\n",
    "        cv2.rectangle(output_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.putText(output_frame, \"Obstacle\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Draw navigation guide lines\n",
    "    cv2.line(output_frame, (left_boundary, H//2), (left_boundary, H), (255, 255, 0), 2)\n",
    "    cv2.line(output_frame, (right_boundary, H//2), (right_boundary, H), (255, 255, 0), 2)\n",
    "    \n",
    "    # Display the final decision\n",
    "    cv2.putText(output_frame, f\"Decision: {decision}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89785711",
   "metadata": {},
   "source": [
    "# Main Real-time Processing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd26b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam opened successfully. Press 'q' on the video window to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oojia\\Downloads\\IDP\\ven\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video stream or webcam error.\n",
      "Webcam released and windows closed.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Process every Nth frame to improve performance and prevent freezing.\n",
    "# A lower number is more accurate but slower. A higher number is faster but less responsive.\n",
    "FRAME_SKIP = 5 \n",
    "\n",
    "# Use 0 for the default built-in webcam\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "else:\n",
    "    print(\"Webcam opened successfully. Press 'q' on the video window to quit.\")\n",
    "    frame_count = 0\n",
    "    last_decision = \"Initializing...\"\n",
    "    \n",
    "    # Initialize variables before the loop to prevent reference-before-assignment on skipped frames\n",
    "    ret, sample_frame = cap.read()\n",
    "    if ret:\n",
    "        H_init, W_init, _ = sample_frame.shape\n",
    "        # Create empty placeholders for the analysis results\n",
    "        safe_path_mask = np.zeros((H_init, W_init), dtype=np.uint8)\n",
    "        human_boxes = []\n",
    "        obstacle_boxes = []\n",
    "    else:\n",
    "        print(\"Error: Could not read the first frame from webcam.\")\n",
    "        cap.release() # Release the webcam if it can't be read\n",
    "\n",
    "    try:\n",
    "        # Set the capture back to the beginning if it was read from\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        \n",
    "        while ret: # Continue as long as we can read frames\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream or webcam error.\")\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # --- Performance Boost: Only process every Nth frame ---\n",
    "            if frame_count % FRAME_SKIP == 0:\n",
    "                # 1. Analyze the scene to get fresh data\n",
    "                safe_path_mask, human_boxes, obstacle_boxes = analyze_scene(\n",
    "                    frame, yolo_model, oneformer_processor, oneformer_model, walkable_ids, device\n",
    "                )\n",
    "                \n",
    "                # 2. Make a new navigation decision and cache it\n",
    "                decision = make_navigation_decision(safe_path_mask, human_boxes, obstacle_boxes, frame.shape[:2])\n",
    "                last_decision = decision \n",
    "            \n",
    "            # 3. Create the visualization using the most recent data\n",
    "            # For skipped frames, this uses the cached data from the last processed frame for a smooth display\n",
    "            output_frame = visualize_output(\n",
    "                frame, safe_path_mask, human_boxes, obstacle_boxes, last_decision\n",
    "            )\n",
    "            \n",
    "            # 4. Display the frame in a new window\n",
    "            cv2.imshow('Real-time Navigation', output_frame)\n",
    "\n",
    "            # 5. Check for 'q' key to exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the loop: {e}\")\n",
    "    finally:\n",
    "        # Release everything when done\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Webcam released and windows closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e38248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from -r requirements.txt (line 3)) (8.3.158)\n",
      "Requirement already satisfied: transformers in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from -r requirements.txt (line 4)) (4.52.4)\n",
      "Requirement already satisfied: accelerate in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from -r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: torch in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from -r requirements.txt (line 6)) (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from -r requirements.txt (line 7)) (0.22.1+cu128)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from -r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (2.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (3.10.3)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (2.0.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (0.33.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 4)) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 4)) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (80.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 9)) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 9)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 9)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 9)) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (0.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 3)) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\oojia\\downloads\\idp\\ven\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 9)) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
